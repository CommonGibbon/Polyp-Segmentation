name: Smoke Test

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  smoke-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry
      uses: snok/install-poetry@v1

    - name: Install dependencies
      run: poetry install

    - name: Configure DVC for public bucket
      run: |
        poetry run dvc remote modify origin url s3://kvasir-seg-dataset-willshannon
        poetry run dvc remote modify origin region us-west-2
        poetry run dvc remote modify origin endpointurl https://s3.us-west-2.amazonaws.com
        poetry run dvc remote modify origin allow_anonymous_login true

    - name: Pull smoke data
      run: |
        # Pull only files referenced in smoke splits
        poetry run python -c "
        import pandas as pd
        import subprocess
        import sys
        from pathlib import Path

        # Read smoke splits
        train_df = pd.read_csv('data/splits_smoke/train.csv')
        val_df = pd.read_csv('data/splits_smoke/val.csv')

        # Get unique file paths
        files = set(train_df['image'].tolist() + train_df['mask'].tolist() +
                   val_df['image'].tolist() + val_df['mask'].tolist())

        # Pull each file
        for file in files:
            if Path(file).exists():
                continue
            print(f'Pulling {file}')
            result = subprocess.run(['poetry', 'run', 'dvc', 'pull', file], capture_output=True)
            if result.returncode != 0:
                print(f'Failed to pull {file}: {result.stderr.decode()}')
                sys.exit(1)
        "

    - name: Run smoke training test
      run: |
        poetry run python -c "
        import torch
        import pandas as pd
        import segmentation_models_pytorch as smp
        from pathlib import Path

        # Test data loading
        train_df = pd.read_csv('data/splits_smoke/train.csv')
        val_df = pd.read_csv('data/splits_smoke/val.csv')
        print(f'âœ… Data loaded: {len(train_df)} train, {len(val_df)} val')

        # Sanity check: a few sample files exist
        for df_name, df in [('train', train_df.head(3)), ('val', val_df.head(3))]:
            for col in ['image', 'mask']:
                for p in df[col].tolist():
                    if not Path(p).exists():
                        raise FileNotFoundError(f'Missing {df_name} {col} file: {p}')
        print('âœ… Sample files exist')

        # Test model creation with minimal config
        model = smp.Unet(
            encoder_name='resnet34',
            encoder_weights=None,  # No pretrained weights for speed
            in_channels=3,
            classes=1
        )
        print('âœ… Model created')

        # Test one forward pass on random input
        x = torch.randn(1, 3, 256, 256)
        with torch.no_grad():
            output = model(x)
        print(f'âœ… Forward pass successful, output shape: {output.shape}')

        print('ðŸŽ‰ All smoke tests passed!')
        "
